{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b595475",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "import torchvision.transforms as tfm\n",
    "\n",
    "import test\n",
    "import util\n",
    "from args_parser import parse_arguments\n",
    "import commons\n",
    "import cosface_loss\n",
    "import augmentations\n",
    "from eigenplaces_model import eigenplaces_network\n",
    "from datasets.test_dataset import TestDataset\n",
    "from datasets.eigenplaces_dataset import EigenPlacesDataset\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # Provides a speedup\n",
    "\n",
    "def main():\n",
    "    args = parse_arguments()\n",
    "    start_time = datetime.now()\n",
    "    output_folder = f\"logs/{args.save_dir}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    commons.make_deterministic(args.seed)\n",
    "    commons.setup_logging(output_folder, console=\"debug\")\n",
    "    logging.info(\" \".join(sys.argv))\n",
    "    logging.info(f\"Arguments: {args}\")\n",
    "    logging.info(f\"The outputs are being saved in {output_folder}\")\n",
    "\n",
    "    #### Model\n",
    "    model = eigenplaces_network.GeoLocalizationNet_(args.backbone, args.fc_output_dim)\n",
    "\n",
    "    logging.info(f\"There are {torch.cuda.device_count()} GPUs and {multiprocessing.cpu_count()} CPUs.\")\n",
    "\n",
    "    if args.resume_model is not None:\n",
    "        logging.debug(f\"Loading model from {args.resume_model}\")\n",
    "        model_state_dict = torch.load(args.resume_model)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "    model = model.to(args.device).train()\n",
    "\n",
    "    #### Optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model_optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #### Datasets\n",
    "    groups = [EigenPlacesDataset(\n",
    "            args.train_dataset_folder, M=args.M, N=args.N, focal_dist=args.focal_dist,\n",
    "            current_group=n//2, min_images_per_class=args.min_images_per_class, \n",
    "            angle=[0, 90][n % 2], visualize_classes=args.visualize_classes)\n",
    "        for n in range(args.groups_num * 2)\n",
    "    ]\n",
    "    # Each group has its own classifier, which depends on the number of classes in the group\n",
    "    classifiers = [cosface_loss.MarginCosineProduct(\n",
    "        args.fc_output_dim, len(group), s=args.s, m=args.m) for group in groups]\n",
    "    classifiers_optimizers = [torch.optim.Adam(classifier.parameters(), lr=args.classifiers_lr) for classifier in classifiers]\n",
    "\n",
    "    gpu_augmentation = tfm.Compose([\n",
    "        augmentations.DeviceAgnosticColorJitter(brightness=args.brightness,\n",
    "                                                contrast=args.contrast,\n",
    "                                                saturation=args.saturation,\n",
    "                                                hue=args.hue),\n",
    "        augmentations.DeviceAgnosticRandomResizedCrop([512, 512],\n",
    "                                                      scale=[1-args.random_resized_crop, 1]),\n",
    "        tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    logging.info(f\"Using {len(groups)} groups\")\n",
    "    logging.info(f\"The {len(groups)} groups have respectively the following \"\n",
    "                 f\"number of classes {[len(g) for g in groups]}\")\n",
    "    logging.info(f\"The {len(groups)} groups have respectively the following \"\n",
    "                 f\"number of images {[g.get_images_num() for g in groups]}\")\n",
    "\n",
    "    logging.info(f\"There are {len(groups[0])} classes for the first group, \" +\n",
    "                 f\"each epoch has {args.iterations_per_epoch} iterations \" +\n",
    "                 f\"with batch_size {args.batch_size}, therefore the model sees each class (on average) \" +\n",
    "                 f\"{args.iterations_per_epoch * args.batch_size / len(groups[0]):.1f} times per epoch\")\n",
    "\n",
    "    val_ds = TestDataset(f\"{args.val_dataset_folder}\")\n",
    "    logging.info(f\"Validation set: {val_ds}\")\n",
    "\n",
    "    #### Resume\n",
    "    if args.resume_train:\n",
    "        model, model_optimizer, classifiers, classifiers_optimizers, \\\n",
    "            best_val_recall1, start_epoch_num = \\\n",
    "                util.resume_train(args, output_folder, model, model_optimizer, \n",
    "                                  classifiers, classifiers_optimizers)\n",
    "\n",
    "        model = model.to(args.device)\n",
    "        epoch_num = start_epoch_num - 1\n",
    "        logging.info(f\"Resuming from epoch {start_epoch_num} with best R@1 {best_val_recall1:.1f} \" +\n",
    "                     f\"from checkpoint {args.resume_train}\")\n",
    "    else:\n",
    "        best_val_recall1 = start_epoch_num = 0\n",
    "\n",
    "    #### Train / evaluation loop\n",
    "    logging.info(\"Start training ...\")\n",
    "\n",
    "    # Use CPU-compatible scaler when running on CPU\n",
    "    if args.device == \"cuda\":\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    for epoch_num in range(start_epoch_num, args.epochs_num):\n",
    "        \n",
    "        #### Train\n",
    "        epoch_start_time = datetime.now()\n",
    "\n",
    "        def get_iterator(groups, classifiers, classifiers_optimizers, batch_size, g_num):\n",
    "            assert len(groups) == len(classifiers) == len(classifiers_optimizers)\n",
    "            classifiers[g_num] = classifiers[g_num].to(args.device)\n",
    "            util.move_to_device(classifiers_optimizers[g_num], args.device)\n",
    "            return commons.InfiniteDataLoader(groups[g_num], num_workers=args.num_workers,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              pin_memory=(args.device == \"cuda\"), drop_last=True)\n",
    "        \n",
    "        # Select classifier and dataloader according to epoch\n",
    "        current_dataset_num = (epoch_num % args.groups_num) * 2\n",
    "        \n",
    "        iterators = []\n",
    "        for i in range(2):\n",
    "            iterators.append(get_iterator(groups, classifiers, classifiers_optimizers,\n",
    "                                             args.batch_size, current_dataset_num + i))\n",
    "        lateral_loss = torchmetrics.MeanMetric()\n",
    "        frontal_loss = torchmetrics.MeanMetric()\n",
    "        \n",
    "        model = model.train()\n",
    "        for iteration in tqdm(range(args.iterations_per_epoch), ncols=100):\n",
    "            model_optimizer.zero_grad()\n",
    "        \n",
    "            #### EigenPlace ITERATION ####\n",
    "            for i in range(2):\n",
    "                classifiers_optimizers[current_dataset_num + i].zero_grad()\n",
    "                \n",
    "                images, targets, _ = next(iterators[i])\n",
    "                images, targets = images.to(args.device), targets.to(args.device)\n",
    "                \n",
    "                if args.device == \"cuda\":\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        images = gpu_augmentation(images)\n",
    "                        descriptors = model(images)\n",
    "                        output = classifiers[current_dataset_num + i](descriptors, targets)\n",
    "                        loss = criterion(output, targets)\n",
    "                        if i == 0:\n",
    "                            loss *= args.lambda_lat\n",
    "                        else:\n",
    "                            loss *= args.lambda_front\n",
    "                else:\n",
    "                    # CPU path without autocast\n",
    "                    images = gpu_augmentation(images)\n",
    "                    descriptors = model(images)\n",
    "                    output = classifiers[current_dataset_num + i](descriptors, targets)\n",
    "                    loss = criterion(output, targets)\n",
    "                    if i == 0:\n",
    "                        loss *= args.lambda_lat\n",
    "                    else:\n",
    "                        loss *= args.lambda_front\n",
    "                \n",
    "                del images, output\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(classifiers_optimizers[current_dataset_num + i])\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    classifiers_optimizers[current_dataset_num + i].step()\n",
    "                \n",
    "                if i == 0:\n",
    "                    lateral_loss.update(loss.detach().cpu())\n",
    "                else:\n",
    "                    frontal_loss.update(loss.detach().cpu())\n",
    "                del loss\n",
    "                #######################\n",
    "        \n",
    "            if scaler is not None:\n",
    "                scaler.step(model_optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                model_optimizer.step()\n",
    "        \n",
    "        for i in range(2):\n",
    "            classifiers[current_dataset_num + i] = classifiers[current_dataset_num + i].cpu()\n",
    "            util.move_to_device(classifiers_optimizers[current_dataset_num + i], \"cpu\")\n",
    "        \n",
    "        logging.debug(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]} - \"\n",
    "                      f\"group {current_dataset_num} lateral_loss = {lateral_loss.compute():.4f} - \"\n",
    "                      f\"group {current_dataset_num + 1} frontal_loss = {frontal_loss.compute():.4f}\")\n",
    "        \n",
    "        #### Evaluation\n",
    "        recalls, recalls_str = test.test(args, val_ds, model, batchify=True)\n",
    "        logging.info(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]}, {val_ds}: {recalls_str}\")\n",
    "        is_best = recalls[0] > best_val_recall1\n",
    "        best_val_recall1 = max(recalls[0], best_val_recall1)\n",
    "        # Save checkpoint, which contains all training parameters\n",
    "        util.save_checkpoint({\n",
    "            \"epoch_num\": epoch_num + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": model_optimizer.state_dict(),\n",
    "            \"classifiers_state_dict\": [c.state_dict() for c in classifiers],\n",
    "            \"optimizers_state_dict\": [c.state_dict() for c in classifiers_optimizers],\n",
    "            \"best_val_recall1\": best_val_recall1\n",
    "        }, is_best, output_folder)\n",
    "\n",
    "    logging.info(f\"Trained for {epoch_num+1:02d} epochs, in total in {str(datetime.now() - start_time)[:-7]}\")\n",
    "\n",
    "    #### Test best model_ on test set v1\n",
    "    best_model_state_dict = torch.load(f\"{output_folder}/best_model.pth\")\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    test_ds = TestDataset(f\"{args.test_dataset_folder}\")\n",
    "    recalls, recalls_str = test.test(args, test_ds, model)\n",
    "    logging.info(f\"{test_ds}: {recalls_str}\")\n",
    "\n",
    "    logging.info(\"Experiment finished (without any errors)\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Windows multiprocessing support\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
